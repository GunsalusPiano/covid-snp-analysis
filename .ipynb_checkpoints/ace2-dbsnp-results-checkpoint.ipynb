{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARS-2 and Human ACE2 Variant Analysis\n",
    "\n",
    "## Purpose\n",
    "The intent of this pipeline is to identify SNVs in publically available, GISAID submitted SARS-2 genomes that differ from the original Wuhan strain. Identified amino acid variants in the S protein were then modeled for their 3D structure and interactions were predicted agains the Human ACE2 receptor and its reported variants.\n",
    "\n",
    "### 1. What are the mutations within the SARS-2 genome and how prevalent are they?\n",
    "In order to identify the mutations that are in circulation we can use the SARS-2 genomes from GISAID and compare them to the established Wuhan strain (the only RefSeq in NCBI). \n",
    "\n",
    "A caveat: I do not know how these genomes are generated but they are presumably MinION data so performing traidional QC is not possible.\n",
    "\n",
    "From there I can use the MUMMER4 package to identify mutations and their subsequent effect on translation.\n",
    "\n",
    "### 2. Do any of these mutations have an effect on the binding affinity to ACE2?\n",
    "Hin Hark is using these mutations in his modeling. I will ask him for a summary of his methods.\n",
    "\n",
    "### 3. What are the mutations within the ACE2 receptor and do they have any effect on the binding affinity to the SARS-2 spike (s) protein?\n",
    "Data for the mutations were obtained from dbSNP and is using the data from the sources mentioned below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNP Analysis\n",
    "\n",
    "To start we are looking only at the spike protein. Using the SARS-2 reference sequence from NCBI I aligned all of the GISAID CDS in protein-space to the reference sequence. I then filtered the alignments to only the first reading frame and removed the ambiguous bases in the resulting SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Format sequence identifier to play nice with Promer\n",
    "perl -pe 's/^.+EPI_ISL_(\\d+).+/>$1/g'  gisaid_hcov-19_2020_05_04_17.fasta | perl -pe 's/-/n/g' > gisaid_hcov-19_2020_05_04_17.refactored.fasta\n",
    "\n",
    "promer -p SARS-2.refseq.cds.s_prot.promer SARS-2.refseq.cds.s_prot.fasta gisaid_cov2020_sequences.refactored.fasta\n",
    "show-coords -clT SARS-2.refseq.cds.s_prot.promer.delta > SARS-2.refseq.cds.s_prot.promer.coords\n",
    "show-snps -STH gisaid_hcov-19_2020_05_04_17.s_prot.promer.delta < <(awk '$14 == \"1\" && $15 == \"1\" { print $0 }' gisaid_hcov-19_2020_05_04_17.s_prot.promer.coords) | cut -f1-3 | sort | uniq -c | sort -nrb | perl -pe 's/ +/\\t/g' | perl -pe 's/^\\s+//g' > gisaid_hcov-19_2020_05_04_17.s_prot.promer.snps-with-nonsense-mutations.counts.tsv\n",
    "# Removes nonsense mutations\n",
    "# show-snps -ST SARS-2.refseq.cds.s_prot.promer.delta < <(awk '$14 == \"1\" && $15 == \"1\" { print $0 }' SARS-2.refseq.cds.s_prot.promer.coords) | grep -v 'X' > SARS-2.refseq.cds.s_prot.promer.snps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsed the dbSNP into a TSV file with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added this into the show-snps one liner above\n",
    "# perl -pe 's/\\n$/\\t/g' snp_result.txt| perl -pe 's/--\\t/\\n/g' | perl -pe 's/\\d+. rs/\\nrs/g' | perl -pe 's/\\r//g' > snp_result.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there I formatted the data into an extended TSV by adding the frequencies of the mutation per data source and extracted the other relevant info (discarding much of it data provided by dbSNP that I deeded irrelevent at this stage in the analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = []\n",
    "\n",
    "import re\n",
    "\n",
    "def check_snp_src(l, src):\n",
    "    index = [i for i, s in enumerate(l) if src in s if i is not \"\"]\n",
    "    if index:\n",
    "        m = re.search(r'0\\.\\d+',l[index[0]])\n",
    "#         print(l[index[0]])\n",
    "#         print (m.group(0))\n",
    "#         print(m)\n",
    "        if m:\n",
    "            return m.group(0)\n",
    "        else:\n",
    "            return 'NA'\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "with open('snp_result.tsv', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        snp = {\n",
    "                'id':'',\n",
    "                'snv':'',\n",
    "                'position':'',\n",
    "                '1000Genomes':'',\n",
    "                'TWINSUK':'',\n",
    "                'GnomAD':'',\n",
    "                'ALSPAC':'',\n",
    "                'TOPMED':''\n",
    "              }\n",
    "        l = line.split('\\t')\n",
    "        snp['id'] = l[0]\n",
    "        snp['snv'] = l[1]\n",
    "        snp['position'] = l[2]\n",
    "        snp['1000Genomes'] = check_snp_src(l,'1000Genomes')\n",
    "        snp['TWINSUK'] = check_snp_src(l,'TWINSUK')\n",
    "        snp['GnomAD'] = check_snp_src(l,'GnomAD')\n",
    "        snp['ALSPAC'] = check_snp_src(l,'ALSPAC')\n",
    "        snp['TOPMED'] = check_snp_src(l,'TOPMED')\n",
    "        \n",
    "#         print(snp)\n",
    "        \n",
    "        snps.append(snp)\n",
    "    \n",
    "# with open('snp_result.cleaned.tsv', 'wb', )\n",
    "df = pandas.DataFrame(snps)\n",
    "df.to_csv('snp_result.cleaned.tsv', sep='\\t', )\n",
    "\n",
    "# print (snps)\n",
    "    \n",
    "#         for i in l:\n",
    "#             if i == l[0]:\n",
    "#                 snp['id'] = l[0]\n",
    "#                 continue\n",
    "#             elif i == l[1]:\n",
    "#                 snp['snv'] = l[1]\n",
    "#                 continue\n",
    "#             elif i == l[2]:\n",
    "#                 snp['position'] = l[2]\n",
    "#                 continue\n",
    "#             elif\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
